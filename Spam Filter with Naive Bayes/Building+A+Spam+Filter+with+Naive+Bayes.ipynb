{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Given my latest studies on Probability and Conditional Probability, I will attemp today to build a spam filter using Naive Bayes.\n",
    "\n",
    "So our first task is to \"teach\" the computer how to classify messages. To do that, we'll use the multinomial Naive Bayes algorithm along with a dataset of 5,572 SMS messages that are already classified by humans.\n",
    "\n",
    "The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the [The UCI Machine Learning Repository](!https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "import re\n",
    "\n",
    "from io import StringIO, BytesIO, TextIOWrapper\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thats the way u feel. Thats the way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>I‘m going to try for 2 months ha ha only joking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>So ü pay first lar... Then when is da stock co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>ham</td>\n",
       "      <td>Armand says get your ass over to epsilon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>ham</td>\n",
       "      <td>U still havent got urself a jacket ah?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm taking derek &amp;amp; taylor to walmart, if I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi its in durban are you still on this number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ic. There are a lotta childporn cars then.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>ham</td>\n",
       "      <td>No, I was trying it all weekend ;V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>ham</td>\n",
       "      <td>You know, wot people wear. T shirts, jumpers, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>ham</td>\n",
       "      <td>Cool, what time you think you can get here?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wen did you get so spiritual and deep. That's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>ham</td>\n",
       "      <td>Have a safe trip to Nigeria. Wish you happines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hahaha..use your brain dear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>ham</td>\n",
       "      <td>Well keep in mind I've only got enough gas for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeh. Indians was nice. Tho it did kane me off ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes i have. So that's why u texted. Pshew...mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>ham</td>\n",
       "      <td>No. I meant the calculation is the same. That ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>ham</td>\n",
       "      <td>if you aren't here in the next  &amp;lt;#&amp;gt;  hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>ham</td>\n",
       "      <td>Anything lor. Juz both of us lor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>ham</td>\n",
       "      <td>Get me out of this dump heap. My mom decided t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lor... Sony ericsson salesman... I ask shuh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ard 6 like dat lor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>Why don't you wait 'til at least wednesday to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>Huh y lei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6      ham  Even my brother is not like to speak with me. ...\n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8     spam  WINNER!! As a valued network customer you have...\n",
       "9     spam  Had your mobile 11 months or more? U R entitle...\n",
       "10     ham  I'm gonna be home soon and i don't want to tal...\n",
       "11    spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "12    spam  URGENT! You have won a 1 week FREE membership ...\n",
       "13     ham  I've been searching for the right words to tha...\n",
       "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "15    spam  XXXMobileMovieClub: To use your credit, click ...\n",
       "16     ham                         Oh k...i'm watching here:)\n",
       "17     ham  Eh u remember how 2 spell his name... Yes i di...\n",
       "18     ham  Fine if thats the way u feel. Thats the way ...\n",
       "19    spam  England v Macedonia - dont miss the goals/team...\n",
       "20     ham          Is that seriously how you spell his name?\n",
       "21     ham    I‘m going to try for 2 months ha ha only joking\n",
       "22     ham  So ü pay first lar... Then when is da stock co...\n",
       "23     ham  Aft i finish my lunch then i go str down lor. ...\n",
       "24     ham  Ffffffffff. Alright no way I can meet up with ...\n",
       "25     ham  Just forced myself to eat a slice. I'm really ...\n",
       "26     ham                     Lol your always so convincing.\n",
       "27     ham  Did you catch the bus ? Are you frying an egg ...\n",
       "28     ham  I'm back &amp; we're packing the car now, I'll...\n",
       "29     ham  Ahhh. Work. I vaguely remember that! What does...\n",
       "...    ...                                                ...\n",
       "5542   ham           Armand says get your ass over to epsilon\n",
       "5543   ham             U still havent got urself a jacket ah?\n",
       "5544   ham  I'm taking derek &amp; taylor to walmart, if I...\n",
       "5545   ham      Hi its in durban are you still on this number\n",
       "5546   ham         Ic. There are a lotta childporn cars then.\n",
       "5547  spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5548   ham                 No, I was trying it all weekend ;V\n",
       "5549   ham  You know, wot people wear. T shirts, jumpers, ...\n",
       "5550   ham        Cool, what time you think you can get here?\n",
       "5551   ham  Wen did you get so spiritual and deep. That's ...\n",
       "5552   ham  Have a safe trip to Nigeria. Wish you happines...\n",
       "5553   ham                        Hahaha..use your brain dear\n",
       "5554   ham  Well keep in mind I've only got enough gas for...\n",
       "5555   ham  Yeh. Indians was nice. Tho it did kane me off ...\n",
       "5556   ham  Yes i have. So that's why u texted. Pshew...mi...\n",
       "5557   ham  No. I meant the calculation is the same. That ...\n",
       "5558   ham                             Sorry, I'll call later\n",
       "5559   ham  if you aren't here in the next  &lt;#&gt;  hou...\n",
       "5560   ham                  Anything lor. Juz both of us lor.\n",
       "5561   ham  Get me out of this dump heap. My mom decided t...\n",
       "5562   ham  Ok lor... Sony ericsson salesman... I ask shuh...\n",
       "5563   ham                                Ard 6 like dat lor.\n",
       "5564   ham  Why don't you wait 'til at least wednesday to ...\n",
       "5565   ham                                       Huh y lei...\n",
       "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset\n",
    "\n",
    "uci_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/\"\n",
    "data_name = \"smsspamcollection.zip\"\n",
    "response = urllib.request.urlopen(uci_url + urllib.request.quote(data_name))\n",
    "\n",
    "zipfile = ZipFile(BytesIO(response.read()))\n",
    "\n",
    "data = TextIOWrapper(zipfile.open('SMSSpamCollection'), encoding= 'utf-8')\n",
    "\n",
    "df = pd.read_csv(data, header= None, sep='\\t')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.rename(columns=\n",
    "          {0:'label',\n",
    "           1:'SMS'},\n",
    "          inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                     SMS\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats= df['label'].value_counts(normalize=True)*100\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 86.5% of entries in the dataset are `ham` (non-spam) and the remaining 13.4% are `spam`. \n",
    "\n",
    "The most common message that in the `ham` is \"Sorry, I'll call later\". Pretty straight forward it is not a spam message, likely to be a quick reply SMS text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Test Set\n",
    "\n",
    "Before we will commence to build the spam filter, it is important to test how well it will work before creating the spam. Creating the spam-detecting software first and testing it after that could lead to biases in test-design.\n",
    "\n",
    "To test the spam filter, we're first going to split our dataset into two categories:\n",
    "\n",
    "- A **training set**, which we'll use to \"train\" the computer how to classify messages.\n",
    "- A **test set**, which we'll use to test how good the spam filter is with classifying new messages.\n",
    "\n",
    "We will use the 80-20 proportion for the training and test data. The split will also help with identifying how good the spam filter actually is at predicting if a message is spam or not. That is because the test set, 20% of the data, has been already classified by a human. When the spam filter will be ready, it will treat this messages as new messages and we will be able to compare the algorithm classification with that done by a human. This will tell us how good the spam filter actually is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n",
      "\n",
      "\n",
      "The percentage of spam in train set is \n",
      " ham     86.54105\n",
      "spam    13.45895\n",
      "Name: label, dtype: float64\n",
      "\n",
      "\n",
      "The percentage of spam in test set is \n",
      " ham     86.804309\n",
      "spam    13.195691\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# randomizing the dataset\n",
    "data_random = df.sample(frac= 1, random_state= 1)\n",
    "\n",
    "# calculating index for split\n",
    "train_size = 0.8\n",
    "train_end = round(len(data_random) * train_size)\n",
    "\n",
    "# Train/Test split\n",
    "df_train = data_random[:train_end].reset_index(drop= True)\n",
    "df_test = data_random[train_end:].reset_index(drop= True)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print('\\n')\n",
    "\n",
    "print(\"The percentage of spam in train set is\", \"\\n\", df_train['label'].value_counts(normalize=True)*100)\n",
    "print(\"\\n\")\n",
    "print(\"The percentage of spam in test set is\", \"\\n\", df_test['label'].value_counts(normalize=True)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                SMS\n",
       "0   ham                       Yep, by the pretty sculpture\n",
       "1   ham      Yes, princess. Are you going to make me moan?\n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent.\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both train and test set have similar percentages of `ham` and `spam` messages. It maintains the percentage ratio from the initial dataset, which would be great in this way to train the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "## Letter Case and Punctuation\n",
    "\n",
    "To make it easier to clean the data, we will have to bring under a form that it is easy to use the Naive Bayes algorithm.\n",
    "\n",
    "It may be the case that message is all of in capitals, has punctuations or non-latin characters. For this, we will be splitting up the messages in the `message` column and transform it in a series of new columns, where each column represents a unique word from the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes princess are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth there s a card on da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                SMS\n",
       "0   ham                        yep by the pretty sculpture\n",
       "1   ham         yes princess are you going to make me moan\n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                             havent\n",
       "4   ham  i forgot 2 ask ü all smth there s a card on da..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanin the SMS column\n",
    "\n",
    "df_train['SMS']= df_train['SMS'].str.replace(\"\\W\", ' ').str.lower().str.replace(' +', ' ').str.strip()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Vocabulary\n",
    "\n",
    "Now that we removed the punctuation and all letters are in lowercase, our end goal is to transform the table above into one where each word has it's own column and it's counted for every `spam` and `ham` message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72427\n"
     ]
    }
   ],
   "source": [
    "# Splitting the words in the message in order to be able to iterate over them later\n",
    "df_train['SMS'] = df_train['SMS'].str.split()\n",
    "\n",
    "vocabulary = []\n",
    "\n",
    "for sms in df_train['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 72427 words in the vocabulary. Since the split was done for each message, there are very high changes that a word will have duplicates. Thus, we will remove those duplicates\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", len(vocabulary),\"words in the vocabulary. Since the split was done for each message, there are very high changes that a word will have duplicates. Thus, we will remove those duplicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  7783  unique words in the vocabulary now.\n"
     ]
    }
   ],
   "source": [
    "# removing duplicates using set() function and then turning it back to a list\n",
    "vocabulary = list(set(vocabulary))\n",
    "\n",
    "print(\"There are \", len(vocabulary),\" unique words in the vocabulary now.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Final Training Set\n",
    "\n",
    "We will create a dictionary called `word_count_per_message` where each key is a unique word from the vocabulary and each value is a list of the length of training set, where each element in the list is a `0`.\n",
    "\n",
    "Then we loop over `df_train['SMS']` to identify the message and its index, and then selecting each word in every sms message and adding it to the dictionary.\n",
    "\n",
    "Then, the dictionary will be transformed in a dataframe that will contain the word count and its index. The index will serve as a connection point to concatinate with the `df_train` dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  00  000  000pes  008704050406  0089  01223585334  02  0207  02072069400  \\\n",
      "0  0   0    0       0             0     0            0   0     0            0   \n",
      "1  0   0    0       0             0     0            0   0     0            0   \n",
      "2  0   0    0       0             0     0            0   0     0            0   \n",
      "3  0   0    0       0             0     0            0   0     0            0   \n",
      "4  0   0    0       0             0     0            0   0     0            0   \n",
      "\n",
      "  ...  zindgi  zoe  zogtorius  zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
      "0 ...       0    0          0     0      0  0   0  0    0  0  \n",
      "1 ...       0    0          0     0      0  0   0  0    0  0  \n",
      "2 ...       0    0          0     0      0  0   0  0    0  0  \n",
      "3 ...       0    0          0     0      0  0   0  0    0  0  \n",
      "4 ...       0    0          0     0      0  0   0  2    0  0  \n",
      "\n",
      "[5 rows x 7783 columns]\n"
     ]
    }
   ],
   "source": [
    "word_counts_per_message = {unique_word: [0] * len(df_train['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(df_train['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_message[word][index] += 1\n",
    "\n",
    "# transforming the dictionary in a dataframe\n",
    "word_counts = pd.DataFrame(word_counts_per_message)\n",
    "print(word_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sculpture: [1, 0, 0, 0, 0]\n",
      "welp: [0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# validating the dictionary count\n",
    "\n",
    "print('sculpture:', word_counts_per_message['sculpture'][0:5])\n",
    "print('welp:', word_counts_per_message['welp'][0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                SMS  0  00  000  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]  0   0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...  0   0    0   \n",
       "2   ham                    [welp, apparently, he, retired]  0   0    0   \n",
       "3   ham                                           [havent]  0   0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  01223585334  02 ...  zindgi  zoe  zogtorius  \\\n",
       "0       0             0     0            0   0 ...       0    0          0   \n",
       "1       0             0     0            0   0 ...       0    0          0   \n",
       "2       0             0     0            0   0 ...       0    0          0   \n",
       "3       0             0     0            0   0 ...       0    0          0   \n",
       "4       0             0     0            0   0 ...       0    0          0   \n",
       "\n",
       "   zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0     0      0  0   0  0    0  0  \n",
       "1     0      0  0   0  0    0  0  \n",
       "2     0      0  0   0  0    0  0  \n",
       "3     0      0  0   0  0    0  0  \n",
       "4     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatinating the dataframes so that we will have the Label and SMS columns\n",
    "df_train = pd.concat([df_train, word_counts], axis= 1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4458, 7785)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72427"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sum(numeric_only=True).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we confirmed that the number of words in the dataframe is the same as the number of words in the vocabulary before elinating the duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Constants First\n",
    "\n",
    "We're now done with cleaning the training set, and we can begin creating the spam filter. The Naive Bayes algorithm will need to answer these two probability questions to be able to classify new messages:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "\\end{equation}\n",
    "\n",
    "Also, to calculate P(wi|Spam) and P(wi|Ham) inside the formulas above, we'll need to use these equations:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam^C) = \\frac{N_{w_i|Spam^C} + \\alpha}{N_{Spam^C} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "Some of the terms in the four equations above will have the same value for every new message. We can calculate the value of these terms once and avoid doing the computations again when a new messages comes in. Below, we'll use our training set to calculate:\n",
    "\n",
    "\\begin{equation} P(Spam)\\ and\\ P(Ham) \\end{equation}\n",
    "    \n",
    "\\begin{equation} NSpam, NHam, NVocabulary \\end{equation}\n",
    "    \n",
    "We'll also use Laplace smoothing and set $\\alpha = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of spam: 0.13458950201884254\n",
      "Probability of non-spam: 0.8654104979811574\n",
      "\n",
      "\n",
      "Number of spam messages: 15190\n",
      "Number of non-spam messages: 57237\n",
      "\n",
      "\n",
      "Number of words in the vocabulary: 7783\n"
     ]
    }
   ],
   "source": [
    "# isolating the spam and ham messages\n",
    "spam_messages = df_train[df_train['label'] == 'spam']\n",
    "ham_messages = df_train[df_train['label'] == 'ham']\n",
    "\n",
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_messages) / len(df_train)\n",
    "p_ham = len(ham_messages) / len(df_train)\n",
    "\n",
    "# Calculating NSpam\n",
    "n_words_per_spam_message = spam_messages['SMS'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "# Calculating NHam\n",
    "n_words_per_ham_message = ham_messages['SMS'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()\n",
    "\n",
    "# Calculating NVocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1\n",
    "\n",
    "print(\"Probability of spam:\", p_spam)\n",
    "print(\"Probability of non-spam:\", p_ham)\n",
    "print('\\n')\n",
    "print('Number of spam messages:', n_spam)\n",
    "print('Number of non-spam messages:', n_ham)\n",
    "print('\\n')\n",
    "print('Number of words in the vocabulary:', n_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Parameters\n",
    "\n",
    "Now that we have the constant terms calculated above, we can move on with calculating the parameters $P(w_i|Spam)$ and $P(w_i|Spam^C)$. Each parameter will thus be a conditional probability value associated with each word in the vocabulary.\n",
    "\n",
    "The parameters are calculated using the formulas:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam^C) = \\frac{N_{w_i|Spam^C} + \\alpha}{N_{Spam^C} + \\alpha \\cdot N_{Vocabulary}}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to some initial errors that I got with the code, I decided to take a manual approach to calculate the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Test for one word (msg) the calculation of conditional probabilities\n",
    "# test_word = 'msg'\n",
    "# test_n_word_given_spam = spam_messages[test_word].sum()\n",
    "# test_p_word_given_spam = (test_n_word_given_spam + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "# test_word_count_total = df_train[test_word].sum()\n",
    "\n",
    "# test_n_word_given_ham = ham_messages[test_word].sum()\n",
    "# test_p_word_given_ham = (test_n_word_given_ham + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "\n",
    "# print(\"Word counts:\")\n",
    "# print('spam: ', test_n_word_given_spam)\n",
    "# print('ham: ', test_n_word_given_ham)\n",
    "# print('total: ', test_word_count_total)\n",
    "# print('_________________')\n",
    "# print('Proportional probabilities:')\n",
    "# print('P(word|spam): ', test_p_word_given_spam)\n",
    "# print('P(word|ham): ', test_p_word_given_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "# Calculating the parameters using the additive smoothing technique\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam_messages[word].sum()\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    parameters_spam[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_given_ham = ham_messages[word].sum()\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha * n_vocabulary)\n",
    "    parameters_ham[word] = p_word_given_ham\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying a New Message\n",
    "\n",
    "With the needed constants and the parameters calculated, we can start creating the actual spam filter. The spam filter can be expressed as function that:\n",
    "- Takes in as input a new message ($w_1$, $w_2$,...,$w_n$), as a string\n",
    "- Perform data cleaning on the new message\n",
    "- Calculates $P(Spam|w_1,w_2,...,w_n)$ and $P(Ham|w_1,w_2,...,w_n)$\n",
    "- Compares the values of $P(Spam|w_1,w_2,...,w_n)$ and $P(Ham|w_1,w_2,...,w_n)$ and:\n",
    "    - if $P(Ham|w_1,w_2,...,w_n)$ > $P(Spam|w_1,w_2,...,w_n)$, then the message is classified as ham\n",
    "    - if $P(Ham|w_1,w_2,...,w_n)$ < $P(Spam|w_1,w_2,...,w_n)$, the the message is classified as spam\n",
    "    - if $P(Ham|w_1,w_2,...,w_n)$ = $P(Spam|w_1,w_2,...,w_n)$, the algorithm may request human intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "    \n",
    "    # Using the same cleaning method as in the test set\n",
    "    message = re.sub(r'\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    # print(message) <- commented after verifying the cleaning\n",
    "    \n",
    "    # Initiating P(Spam|message) and P(Ham|message) with the initial values of\n",
    "    # p_spam and p_ham\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    # Iterate over the words in the message. In case it is a known word, \n",
    "    # multiply with the respective proportional probabilities\n",
    "    for word in message:\n",
    "        if word in vocabulary:\n",
    "            p_spam_given_message = p_spam_given_message * parameters_spam[word]\n",
    "            p_ham_given_message = p_ham_given_message * parameters_ham[word]\n",
    "#         else:\n",
    "#             print(\"The word '\", word, \"' was not found. Calculations ignored.\")\n",
    "    \n",
    "    # Classification of the word\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        result = 'Not Spam'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        result = 'Spam'\n",
    "    elif p_ham_given_message == p_spam_given_message:\n",
    "        result = 'Needs human check'\n",
    "        \n",
    "\n",
    "    return p_ham_given_message, p_spam_given_message, result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The message is: WINNER!! This is the secret code to unlock the money: C3421.\n",
      "Probability that this message is spam: 1.9368049028589875e-27\n",
      "Probability that this message isn't spam: 1.3481290211300841e-25\n",
      "Classification: Spam\n",
      "\n",
      "\n",
      "The message is: Sounds good, Tom, then see u there\n",
      "Probability that this message is spam: 1.9368049028589875e-27\n",
      "Probability that this message isn't spam: 1.3481290211300841e-25\n",
      "Classification: Spam\n"
     ]
    }
   ],
   "source": [
    "test_message1 = 'WINNER!! This is the secret code to unlock the money: C3421.'\n",
    "\n",
    "print(\"The message is:\", test_message1)\n",
    "message_p_spam, message_p_not_spam, classification = classify(test_message1)\n",
    "print(\"Probability that this message is spam:\", message_p_spam)\n",
    "print(\"Probability that this message isn't spam:\", message_p_not_spam)\n",
    "print(\"Classification:\", classification)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "test_message2 = \"Sounds good, Tom, then see u there\"\n",
    "\n",
    "print(\"The message is:\", test_message2)\n",
    "message_p_spam, message_p_not_spam, classification = classify(test_message1)\n",
    "print(\"Probability that this message is spam:\", message_p_spam)\n",
    "print(\"Probability that this message isn't spam:\", message_p_not_spam)\n",
    "print(\"Classification:\", classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function classifies the messages correctly. Let's now try it on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Measuring the Spam Filter's Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the `df_test` dataframe that we created in the beginning to test the spam filter. We know that a human classified each message. Our algorithm will run through the test dataset for the first time and will attempt to classify each message. Thus, we will be able to asses how well our spam filter performs.\n",
    "\n",
    "We will create 3 new columns:\n",
    "- `p_spam` and `p_ham` where we will insert the probability\n",
    "- `classification` column where we will input the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>p_spam</th>\n",
       "      <th>p_ham</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>to do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>to do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>to do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>to do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>to do</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                SMS  p_spam  p_ham  \\\n",
       "0   ham          Later i guess. I needa do mcat study too.       0      0   \n",
       "1   ham             But i haf enuff space got like 4 mb...       0      0   \n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...       0      0   \n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       0      0   \n",
       "4   ham  All done, all handed in. Don't know if mega sh...       0      0   \n",
       "\n",
       "  classification  \n",
       "0          to do  \n",
       "1          to do  \n",
       "2          to do  \n",
       "3          to do  \n",
       "4          to do  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing the columns\n",
    "df_test['p_spam'] = 0\n",
    "df_test['p_ham'] = 0\n",
    "df_test['classification'] = 'to do'\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Spam             969\n",
      "Spam                 144\n",
      "Needs human check      1\n",
      "Name: classification, dtype: int64\n",
      "\n",
      "\n",
      "Not Spam             86.983842\n",
      "Spam                 12.926391\n",
      "Needs human check     0.089767\n",
      "Name: classification, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Filling the columns with the values from the classify function\n",
    "df_test['p_spam'] = df_test['SMS'].apply(lambda SMS:classify(SMS)[0])\n",
    "df_test['p_ham'] = df_test['SMS'].apply(lambda SMS: classify(SMS)[1])\n",
    "df_test['classification'] = df_test['SMS'].apply(lambda SMS: classify(SMS)[2])\n",
    "\n",
    "# Summary statistics\n",
    "print(df_test['classification'].value_counts())\n",
    "print('\\n')\n",
    "print(df_test['classification'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>p_spam</th>\n",
       "      <th>p_ham</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>ham</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Needs human check</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                                SMS  p_spam  p_ham  \\\n",
       "293   ham  A Boy loved a gal. He propsd bt she didnt mind...     0.0    0.0   \n",
       "\n",
       "        classification  \n",
       "293  Needs human check  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The un\n",
    "df_test[df_test['classification']=='Needs human check']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportioonal values seems to be what we were expecting them to be. There is one message where a human would need to check and decide the classification because the probability of that message being a spam is equal with the probability of not being a spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>p_spam</th>\n",
       "      <th>p_ham</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>4.253245e-19</td>\n",
       "      <td>3.483107e-26</td>\n",
       "      <td>Not Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>9.669411e-29</td>\n",
       "      <td>3.113881e-34</td>\n",
       "      <td>Not Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>4.338466e-98</td>\n",
       "      <td>7.548550e-83</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>1.481496e-28</td>\n",
       "      <td>3.608708e-34</td>\n",
       "      <td>Not Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>6.581143e-58</td>\n",
       "      <td>2.764395e-68</td>\n",
       "      <td>Not Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>But my family not responding for anything. Now...</td>\n",
       "      <td>1.396866e-88</td>\n",
       "      <td>3.003832e-110</td>\n",
       "      <td>Not Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>U too...</td>\n",
       "      <td>1.536822e-05</td>\n",
       "      <td>6.630543e-08</td>\n",
       "      <td>Not Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>Boo what time u get out? U were supposed to ta...</td>\n",
       "      <td>9.822271e-39</td>\n",
       "      <td>1.675016e-44</td>\n",
       "      <td>Not Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Genius what's up. How your brother. Pls send h...</td>\n",
       "      <td>5.700660e-36</td>\n",
       "      <td>1.293839e-42</td>\n",
       "      <td>Not Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ham</td>\n",
       "      <td>I liked the new mobile</td>\n",
       "      <td>6.458119e-15</td>\n",
       "      <td>1.029835e-15</td>\n",
       "      <td>Not Spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                SMS        p_spam  \\\n",
       "0   ham          Later i guess. I needa do mcat study too.  4.253245e-19   \n",
       "1   ham             But i haf enuff space got like 4 mb...  9.669411e-29   \n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...  4.338466e-98   \n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...  1.481496e-28   \n",
       "4   ham  All done, all handed in. Don't know if mega sh...  6.581143e-58   \n",
       "5   ham  But my family not responding for anything. Now...  1.396866e-88   \n",
       "6   ham                                           U too...  1.536822e-05   \n",
       "7   ham  Boo what time u get out? U were supposed to ta...  9.822271e-39   \n",
       "8   ham  Genius what's up. How your brother. Pls send h...  5.700660e-36   \n",
       "9   ham                             I liked the new mobile  6.458119e-15   \n",
       "\n",
       "           p_ham classification  \n",
       "0   3.483107e-26       Not Spam  \n",
       "1   3.113881e-34       Not Spam  \n",
       "2   7.548550e-83           Spam  \n",
       "3   3.608708e-34       Not Spam  \n",
       "4   2.764395e-68       Not Spam  \n",
       "5  3.003832e-110       Not Spam  \n",
       "6   6.630543e-08       Not Spam  \n",
       "7   1.675016e-44       Not Spam  \n",
       "8   1.293839e-42       Not Spam  \n",
       "9   1.029835e-15       Not Spam  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sample above it seems that all the messages are classified correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add a new column to the dataframe, one which will help us identify whether or not the spam classifier has correctedtly identified the spam as good as the human classification. This will enable us to isolate the examples where the classification was not correctedly done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_correct(row):\n",
    "    output = 'Not decided'\n",
    "    \n",
    "    if row['label'] == 'spam':\n",
    "        if row['classification'] == 'Spam':\n",
    "            output = 'Correct'\n",
    "        if row['classification'] == 'Not Spam':\n",
    "            output = 'Incorrect'\n",
    "\n",
    "    if row['label'] == 'ham':\n",
    "        if row['classification'] == 'Spam':\n",
    "            output = 'Incorrect'\n",
    "        if row['classification'] == 'Not Spam':\n",
    "            output = 'Correct'\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Correct'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_correct(df_test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test['correctness'] = 'To be checked'\n",
    "df_test['correctness'] = df_test.apply(is_correct, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>p_spam</th>\n",
       "      <th>p_ham</th>\n",
       "      <th>classification</th>\n",
       "      <th>correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>4.253245e-19</td>\n",
       "      <td>3.483107e-26</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>9.669411e-29</td>\n",
       "      <td>3.113881e-34</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>4.338466e-98</td>\n",
       "      <td>7.548550e-83</td>\n",
       "      <td>Spam</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>1.481496e-28</td>\n",
       "      <td>3.608708e-34</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>6.581143e-58</td>\n",
       "      <td>2.764395e-68</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>But my family not responding for anything. Now...</td>\n",
       "      <td>1.396866e-88</td>\n",
       "      <td>3.003832e-110</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>U too...</td>\n",
       "      <td>1.536822e-05</td>\n",
       "      <td>6.630543e-08</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>Boo what time u get out? U were supposed to ta...</td>\n",
       "      <td>9.822271e-39</td>\n",
       "      <td>1.675016e-44</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Genius what's up. How your brother. Pls send h...</td>\n",
       "      <td>5.700660e-36</td>\n",
       "      <td>1.293839e-42</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ham</td>\n",
       "      <td>I liked the new mobile</td>\n",
       "      <td>6.458119e-15</td>\n",
       "      <td>1.029835e-15</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                SMS        p_spam  \\\n",
       "0   ham          Later i guess. I needa do mcat study too.  4.253245e-19   \n",
       "1   ham             But i haf enuff space got like 4 mb...  9.669411e-29   \n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...  4.338466e-98   \n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...  1.481496e-28   \n",
       "4   ham  All done, all handed in. Don't know if mega sh...  6.581143e-58   \n",
       "5   ham  But my family not responding for anything. Now...  1.396866e-88   \n",
       "6   ham                                           U too...  1.536822e-05   \n",
       "7   ham  Boo what time u get out? U were supposed to ta...  9.822271e-39   \n",
       "8   ham  Genius what's up. How your brother. Pls send h...  5.700660e-36   \n",
       "9   ham                             I liked the new mobile  6.458119e-15   \n",
       "\n",
       "           p_ham classification correctness  \n",
       "0   3.483107e-26       Not Spam     Correct  \n",
       "1   3.113881e-34       Not Spam     Correct  \n",
       "2   7.548550e-83           Spam     Correct  \n",
       "3   3.608708e-34       Not Spam     Correct  \n",
       "4   2.764395e-68       Not Spam     Correct  \n",
       "5  3.003832e-110       Not Spam     Correct  \n",
       "6   6.630543e-08       Not Spam     Correct  \n",
       "7   1.675016e-44       Not Spam     Correct  \n",
       "8   1.293839e-42       Not Spam     Correct  \n",
       "9   1.029835e-15       Not Spam     Correct  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct        1100\n",
      "Incorrect        13\n",
      "Not decided       1\n",
      "Name: correctness, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_test['correctness'].value_counts())\n",
    "print('\\n')\n",
    "\n",
    "# this also gives our accuracy for the model, but for learning purposes \n",
    "# I will use another method\n",
    "# print(df_test['correctness'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results seem to be quite good. Let's investigate the rows where the classification was incorrect and not decided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>p_spam</th>\n",
       "      <th>p_ham</th>\n",
       "      <th>classification</th>\n",
       "      <th>correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>ham</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Needs human check</td>\n",
       "      <td>Not decided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>ham</td>\n",
       "      <td>Unlimited texts. Limited minutes.</td>\n",
       "      <td>1.385268e-12</td>\n",
       "      <td>1.054585e-11</td>\n",
       "      <td>Spam</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>ham</td>\n",
       "      <td>26th OF JULY</td>\n",
       "      <td>1.319153e-12</td>\n",
       "      <td>5.328430e-12</td>\n",
       "      <td>Spam</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nokia phone is lovly..</td>\n",
       "      <td>3.341645e-10</td>\n",
       "      <td>3.230228e-09</td>\n",
       "      <td>Spam</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>3.030822e-18</td>\n",
       "      <td>9.486266e-18</td>\n",
       "      <td>Spam</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>ham</td>\n",
       "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
       "      <td>1.386787e-60</td>\n",
       "      <td>2.949867e-58</td>\n",
       "      <td>Spam</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>spam</td>\n",
       "      <td>Not heard from U4 a while. Call me now am here...</td>\n",
       "      <td>1.181554e-84</td>\n",
       "      <td>1.999536e-94</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>spam</td>\n",
       "      <td>More people are dogging in your area now. Call...</td>\n",
       "      <td>2.035339e-78</td>\n",
       "      <td>1.004189e-78</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "      <td>1.627774e-66</td>\n",
       "      <td>2.637158e-73</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>5.839167e-95</td>\n",
       "      <td>4.053603e-100</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>spam</td>\n",
       "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
       "      <td>9.608184e-69</td>\n",
       "      <td>3.199788e-72</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>spam</td>\n",
       "      <td>RCT' THNQ Adrian for U text. Rgds Vatian</td>\n",
       "      <td>5.885659e-08</td>\n",
       "      <td>2.089055e-08</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>spam</td>\n",
       "      <td>2/2 146tf150p</td>\n",
       "      <td>1.415923e-05</td>\n",
       "      <td>7.027356e-06</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
       "      <td>2.281984e-61</td>\n",
       "      <td>6.041255e-71</td>\n",
       "      <td>Not Spam</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                                SMS        p_spam  \\\n",
       "293   ham  A Boy loved a gal. He propsd bt she didnt mind...  0.000000e+00   \n",
       "152   ham                  Unlimited texts. Limited minutes.  1.385268e-12   \n",
       "159   ham                                       26th OF JULY  1.319153e-12   \n",
       "284   ham                             Nokia phone is lovly..  3.341645e-10   \n",
       "302   ham                   No calls..messages..missed calls  3.030822e-18   \n",
       "319   ham  We have sent JD for Customer Service cum Accou...  1.386787e-60   \n",
       "114  spam  Not heard from U4 a while. Call me now am here...  1.181554e-84   \n",
       "135  spam  More people are dogging in your area now. Call...  2.035339e-78   \n",
       "504  spam  Oh my god! I've found your number again! I'm s...  1.627774e-66   \n",
       "546  spam  Hi babe its Chloe, how r u? I was smashed on s...  5.839167e-95   \n",
       "741  spam  0A$NETWORKS allow companies to bill for SMS, s...  9.608184e-69   \n",
       "876  spam           RCT' THNQ Adrian for U text. Rgds Vatian  5.885659e-08   \n",
       "885  spam                                      2/2 146tf150p  1.415923e-05   \n",
       "953  spam  Hello. We need some posh birds and chaps to us...  2.281984e-61   \n",
       "\n",
       "             p_ham     classification  correctness  \n",
       "293   0.000000e+00  Needs human check  Not decided  \n",
       "152   1.054585e-11               Spam    Incorrect  \n",
       "159   5.328430e-12               Spam    Incorrect  \n",
       "284   3.230228e-09               Spam    Incorrect  \n",
       "302   9.486266e-18               Spam    Incorrect  \n",
       "319   2.949867e-58               Spam    Incorrect  \n",
       "114   1.999536e-94           Not Spam    Incorrect  \n",
       "135   1.004189e-78           Not Spam    Incorrect  \n",
       "504   2.637158e-73           Not Spam    Incorrect  \n",
       "546  4.053603e-100           Not Spam    Incorrect  \n",
       "741   3.199788e-72           Not Spam    Incorrect  \n",
       "876   2.089055e-08           Not Spam    Incorrect  \n",
       "885   7.027356e-06           Not Spam    Incorrect  \n",
       "953   6.041255e-71           Not Spam    Incorrect  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_classification = df_test[df_test['correctness'] != 'Correct'].sort_values(['label', 'classification'])\n",
    "incorrect_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to see those examples in according to the classification done by the algorithm. Some messages are quite close to eachother, but other have an `E-61` and `E-71` which means that there is a difference of 10,000,000,000 between them.\n",
    "\n",
    "The example where correctness was `Not decided` is quite straightforward, since the probabilities are equal to each other. Or so it may seem, since there could be that the multiplication of so many small words went beyond computer's ability to handle and show them. Since it is just 1 of the 5k messages, we can go over it.\n",
    "\n",
    "Let's now calculate the accuracy of our classifier using another method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy is 98.74%\n",
      "Accuracy for spam messages is 94.56%\n",
      "Accuracy for non-spam messages is 99.38%\n"
     ]
    }
   ],
   "source": [
    "total = len(df_test)\n",
    "spam_total = len(df_test[df_test['label'] == 'spam'])\n",
    "nonspam_total = len(df_test[df_test['label'] == 'ham'])\n",
    "\n",
    "# Count the correctly classified messages\n",
    "correct_spam_total = len(df_test[(df_test['label'] == 'spam') & (df_test['classification'] == 'Spam')])\n",
    "correct_nonspam_total = len(df_test[(df_test['label'] == 'ham') & (df_test['classification'] == 'Not Spam')])\n",
    "correct_total = correct_spam_total + correct_nonspam_total\n",
    "\n",
    "#Calculate the accuracy\n",
    "accuracy_overall = correct_total / total\n",
    "accuracy_spam = correct_spam_total / spam_total\n",
    "accuracy_nonspam = correct_nonspam_total / nonspam_total\n",
    "\n",
    "print(\"Overall accuracy is {:.2%}\".format(accuracy_overall))\n",
    "print(\"Accuracy for spam messages is {:.2%}\".format(accuracy_spam))\n",
    "print(\"Accuracy for non-spam messages is {:.2%}\".format(accuracy_nonspam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall accuracy is almost 99% for the messages in test set. That is a quite good score and I am pleased with it.\n",
    "\n",
    "As we could have seen with the spam messages above, they can get pretty well at creating a message so that it passes a spam filter. With the current accuracy, a spam filter still has 5.44% chances of passing as non-spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and next steps\n",
    "\n",
    "The project's aim was to build a spam filter for SMS messages using the Naive Bayes algorithm. We processed a dataset of approx. 5000 SMS, we split it in train and test datasets, we cleaned the data and used individual word in the training set to create a vocabulary of words, on which we applied Naive Bayes algorithm to calculate the probability that a message would be `spam` or `ham`. From my personal experience, a model accuracy of 80% and above is good but the accuracy of this algorithm has been close to 99%.\n",
    "\n",
    "## Next steps\n",
    "\n",
    "\n",
    "- Isolate the 14 messages that were classified incorrectly and try to figure out why the algorithm reached the wrong conclusions.\n",
    "- Make the filtering process more complex by making the algorithm sensitive to letter case.\n",
    "\n",
    "\n",
    "I will get back to this project at later stage, while now I have to get to finish another project about K-Means Clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
